{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f547d75-e73c-43a2-90b8-516ab5ef59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d3c47f-1001-4c99-b269-51bccecea279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b47eb75-4dba-4b3e-90c3-7ebefb6d5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6a596a-c127-426e-b82f-3c34864d8725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/backyard.csv', 'data/frontyard.csv', 'data/garage.csv', 'data/kitchen.csv', 'data/livingroom.csv']\n"
     ]
    }
   ],
   "source": [
    "areas =  ['backyard', 'frontyard', 'garage', 'kitchen', 'livingroom']\n",
    "data_files = [f'data/{area}.csv' for area in areas]\n",
    "print(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ecabd1-6298-425e-be5a-d8b7f43a16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df = df[df['state'] != 'unavailable']\n",
    "    df.rename(columns={'last_changed': 'datetime'}, inplace = True)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "    df['second'] = df['datetime'].dt.second\n",
    "    df['minute'] = df['datetime'].dt.minute\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['dayofweek'] = df['datetime'].dt.day\n",
    "    df['weekofmonth'] = (df['datetime'].dt.day - 1) // 7 + 1\n",
    "    df['monthofyear'] = df['datetime'].dt.month\n",
    "    df_switches = df[df['state'].isin({'on', 'off'})]\n",
    "    df_sensors = df[df['entity_id'].str.contains(\"sensor\")]\n",
    "    df_sensors = df_sensors[df_sensors['entity_id'].str.contains('status|last_seen') == False]\n",
    "    return df_switches, df_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c893802a-3390-4031-a208-3d328587b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(data_files):\n",
    "    df_switches_list = []\n",
    "    df_sensors_list = []\n",
    "    for data in [read_and_clean(fname) for fname in data_files]:\n",
    "        df_switches_list.append(data[0])\n",
    "        df_sensors_list.append(data[1])\n",
    "    df_sensors_combined = pd.concat(df_sensors_list)\n",
    "    df_sensors_combined['type'] = 0 # sensor\n",
    "    # correctly factorize the mixed states (numerical, timestamp and categorial states)\n",
    "    categorical_state_mask = pd.to_numeric(df_sensors_combined['state'], errors='coerce').isnull()\n",
    "    numerical_state_mask = ~categorical_state_mask\n",
    "    df_sensors_combined.loc[categorical_state_mask, 'state'], unique_sensor_states = pd.factorize(df_sensors_combined['state'][categorical_state_mask])\n",
    "    df_sensors_combined.loc[numerical_state_mask, 'state'] = pd.to_numeric(df_sensors_combined['state'][numerical_state_mask])\n",
    "    df_switches_combined = pd.concat(df_switches_list)\n",
    "    df_switches_combined['type'] = 1 # event\n",
    "    df_switches_combined['state'], unique_event_states = pd.factorize(df_switches_combined['state'])\n",
    "    df_combined = pd.concat([df_switches_combined, df_sensors_combined])\n",
    "    df_combined['entity_id'], unique_entity_ids = pd.factorize(df_combined['entity_id'])\n",
    "    df_combined = df_combined.sort_values(by='datetime')\n",
    "    return df_combined, df_sensors_combined, df_switches_combined, unique_sensor_states, unique_entity_ids, unique_event_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dda555d-e111-4380-b431-9af9e5dec727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "def build_sequence(data_files):\n",
    "    df_combined, df_sensors_combined, df_switches_combined, unique_sensor_states, unique_entity_ids, unique_event_states = combine_data(data_files)\n",
    "    timestamps = df_combined['datetime'].values\n",
    "    data = df_combined.drop('datetime', axis=1).values \n",
    "    type_loc = df_combined.drop('datetime', axis=1).columns.get_loc('type')\n",
    "    entity_id_loc = df_combined.drop('datetime', axis=1).columns.get_loc('entity_id')\n",
    "    state_loc = df_combined.drop('datetime', axis=1).columns.get_loc('state')\n",
    "    # Parameters\n",
    "    window_size_seconds = 300  # 5 mins = 86400 seconds\n",
    "    step_size = 1  # 1-second step size\n",
    "    \n",
    "    # Prepare to store windows\n",
    "    input_sequences = []\n",
    "    action_device_sequences = []\n",
    "    action_state_sequences = []\n",
    "    action_timing_sequences = []\n",
    "    for i in tqdm(range(len(timestamps))):\n",
    "        # Define the end time for the current window\n",
    "        end_time = timestamps[i] + pd.Timedelta(seconds=window_size_seconds)\n",
    "    \n",
    "        # Collect data for the current window\n",
    "        window_data = []\n",
    "        last_pos = i\n",
    "        for j in range(i, len(timestamps)):\n",
    "            if timestamps[j] <= end_time:\n",
    "                last_pos = j\n",
    "                window_data.append(data[j].astype('float'))\n",
    "            else:\n",
    "                break  # Stop if we exceed the window time\n",
    "        \n",
    "        # Append to the sequences if the window is not empty\n",
    "        # minimum number of snesory/action data needed is 10\n",
    "        if len(window_data) < 10 or window_data[-1][type_loc] != 1: continue\n",
    "        input_seq = window_data[:-1]\n",
    "        input_sequences.append(input_seq)\n",
    "        action_device_sequences.append(window_data[-1][entity_id_loc])\n",
    "        action_state_sequences.append(window_data[-1][state_loc])\n",
    "        timing = (timestamps[last_pos] - timestamps[last_pos-2]).astype('timedelta64[s]').astype('int64')\n",
    "        action_timing_sequences.append(timing)\n",
    "    return (input_sequences, action_device_sequences, action_state_sequences, action_timing_sequences, unique_sensor_states, unique_entity_ids, unique_event_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e2d9f33-66f6-40bd-b65f-6d0781be51ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 88449/88449 [00:36<00:00, 2444.65it/s]\n"
     ]
    }
   ],
   "source": [
    "input_sequences, action_device_sequences, action_state_sequences, action_timing_sequences, unique_sensor_states, unique_entity_ids, unique_event_states = build_sequence(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "954522ac-db99-4464-9d60-0e501e869319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 23414, number of device/state/timing: 23414/23414/23414\n"
     ]
    }
   ],
   "source": [
    "print(f'number of sequences: {len(input_sequences)}, number of device/state/timing: {len(action_device_sequences)}/{len(action_state_sequences)}/{len(action_timing_sequences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f722331d-2262-45a5-9262-9329b3e7b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_tensors = [torch.tensor(input_sequence).to(torch.float32) for input_sequence in input_sequences]\n",
    "act_dev_tensors = [torch.tensor(dev).to(torch.float32) for dev in action_device_sequences]\n",
    "act_state_tensors = [torch.tensor(state).to(torch.float32) for state in action_state_sequences]\n",
    "act_timing_tensors = [torch.tensor(timing).to(torch.float32) for timing in action_timing_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd4d1819-ec70-48de-840e-b4b6ad263206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique actionalble devices: 30, number of actionable state: 2\n",
      "number of features: 9\n"
     ]
    }
   ],
   "source": [
    "## ok some stats\n",
    "actionable_devices = set([act for act in action_device_sequences])\n",
    "n_act_dev = len(actionable_devices)\n",
    "actionable_states = unique_event_states\n",
    "n_act_state = len(actionable_states)\n",
    "print(f'number of unique actionalble devices: {n_act_dev}, number of actionable state: {n_act_state}')\n",
    "n_features = len(input_sequences[0][0])\n",
    "print(f'number of features: {n_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f797e053-d822-4f2b-8fc1-f23b3939a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_tensors, 'input_seq_tensors.pt')\n",
    "torch.save(act_dev_tensors, 'act_dev_tensors.pt')\n",
    "torch.save(act_state_tensors, 'act_state_tensors.pt')\n",
    "torch.save(act_timing_tensors, 'act_timing_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e44c793-0289-4f68-990e-8145c6f15f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_entity_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
