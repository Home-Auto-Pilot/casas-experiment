{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851ff166-7479-46c3-8736-b7325cd8e753",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hap import HomeAutoPilot\n",
    "from hap_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad454e-c013-43d9-ac59-4ae3883591f2",
   "metadata": {},
   "source": [
    "# data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb64318-79ed-4985-93dd-e12c2003ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 15453/15453 [00:01<00:00, 8197.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique actionalble devices: 94, number of actionable state: 2\n",
      "number of features: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/root/workspaces/hap/hap_util.py:105: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  input_tensors = [torch.tensor(input_sequence).to(torch.float32) for input_sequence in input_sequences]\n"
     ]
    }
   ],
   "source": [
    "areas =  ['backyard', 'frontyard', 'garage', 'kitchen', 'livingroom']\n",
    "data_files = [f'../data/{area}.csv' for area in areas]\n",
    "input_tensors, act_dev_tensors, act_state_tensors, act_timing_tensors, n_features, n_act_state, n_act_dev, unique_entity_ids, unique_event_states = prep_tensors(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d854fe-cfa1-4aba-a57b-893040b92f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensors = torch.load('input_seq_tensors.pt', weights_only=True)\n",
    "act_dev_tensors = torch.load('act_dev_tensors.pt', weights_only=True)\n",
    "act_state_tensors = torch.load('act_state_tensors.pt', weights_only=True)\n",
    "act_timing_tensors = torch.load('act_timing_tensors.pt', weights_only=True)\n",
    "device_id_map = torch.load('device_id_map.pt', weights_only=False)\n",
    "device_state_id_map = torch.load('device_state_map.pt', weights_only=False)\n",
    "\n",
    "n_act_state = len(device_state_id_map)\n",
    "n_act_dev = len(device_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698706b-7d71-4e39-9776-cde1cfb1b950",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# run inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f2459af-3b90-4502-8715-c1416f15c20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hap:Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# re-create the model\n",
    "pilot = HomeAutoPilot(num_devices = n_act_dev, num_device_actions = n_act_state)\n",
    "pilot.load_model('pilot_demo2.ptmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b19bf476-7307-4548-8938-003c67ca94f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: Turn switch.garage_light on after 8.813950538635254 seconds\n",
      "----ground truth----\n",
      "ground turth: Turn light.garage_lamp off after 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample_idx = random.choice(range(len(input_tensors)))\n",
    "input_tensor = input_tensors[sample_idx]\n",
    "predicted_timing, predicted_device_idx, predicted_action_idx = pilot.eval(input_tensor)\n",
    "device_name = device_id_map[predicted_device_idx]\n",
    "action_name = device_state_id_map[predicted_action_idx]\n",
    "\n",
    "print(f'prediction: Turn {device_name} {action_name} after {predicted_timing} seconds')\n",
    "print('----ground truth----')\n",
    "gt_dev_name = device_id_map[act_dev_tensors[sample_idx].int().item()]\n",
    "gt_action_name = device_state_id_map[act_state_tensors[sample_idx].int().item()]\n",
    "gt_timing = act_timing_tensors[sample_idx].item()\n",
    "print(f'ground turth: Turn {gt_dev_name} {gt_action_name} after {gt_timing} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb2f43-f18a-42eb-add5-3e1c5f0f4cfa",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29fbb8aa-4b10-4d1f-aa25-939c41fc6d6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hap:Using device: cuda\n",
      "3it [00:00, 92.17it/s]\n",
      "INFO:hap:Epoch [1/10], Loss: 1435.6392\n",
      "3it [00:00, 93.40it/s]\n",
      "INFO:hap:Epoch [2/10], Loss: 2411.0146\n",
      "3it [00:00, 114.82it/s]\n",
      "INFO:hap:Epoch [3/10], Loss: 435.6131\n",
      "3it [00:00, 96.89it/s]\n",
      "INFO:hap:Epoch [4/10], Loss: 1375.7239\n",
      "3it [00:00, 92.91it/s]\n",
      "INFO:hap:Epoch [5/10], Loss: 1487.9615\n",
      "3it [00:00, 99.71it/s]\n",
      "INFO:hap:Epoch [6/10], Loss: 5067.0942\n",
      "3it [00:00, 82.89it/s]\n",
      "INFO:hap:Epoch [7/10], Loss: 259.8890\n",
      "3it [00:00, 104.70it/s]\n",
      "INFO:hap:Epoch [8/10], Loss: 9946.4688\n",
      "3it [00:00, 97.10it/s]\n",
      "INFO:hap:Epoch [9/10], Loss: 1007.7250\n",
      "3it [00:00, 105.69it/s]\n",
      "INFO:hap:Epoch [10/10], Loss: 8514.4121\n",
      "INFO:hap:Test Loss: 4217.8364\n",
      "INFO:hap:Device Prediction Accuracy: 0.6250\n",
      "INFO:hap:Action Prediction Accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "pilot = HomeAutoPilot(num_devices = n_act_dev, num_device_actions = n_act_state)\n",
    "pilot.train_model(input_tensors, act_dev_tensors, act_state_tensors, act_timing_tensors, train_epoch = 10, model_path = 'pilot_demo2.ptmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d5b8f6-261b-478f-952d-832571a64e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
